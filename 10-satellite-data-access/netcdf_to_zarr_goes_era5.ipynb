{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter some warning messages\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "#libraries\n",
    "import datetime as dt\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import s3fs\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# make datasets display nicely\n",
    "xr.set_options(display_style=\"html\")  \n",
    "import os.path\n",
    "\n",
    "#magic fncts #put static images of your plot embedded in the notebook\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "%config InlineBackend.figure_format = 'retina' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_data(sat,lyr,idyjl):\n",
    "    # arguments\n",
    "    # sat   goes-east,goes-west,himawari\n",
    "    # lyr   year\n",
    "    # idyjl day of year\n",
    "    \n",
    "    d = dt.datetime(lyr,1,1) + dt.timedelta(days=idyjl)\n",
    "    fs = s3fs.S3FileSystem(anon=True) #connect to s3 bucket!\n",
    "\n",
    "    #create strings for the year and julian day\n",
    "    imon,idym=d.month,d.day\n",
    "    syr,sjdy,smon,sdym = str(lyr).zfill(4),str(idyjl).zfill(3),str(imon).zfill(2),str(idym).zfill(2)\n",
    "    \n",
    "    #use glob to list all the files in the directory\n",
    "    if sat=='goes-east':\n",
    "        file_location,var = fs.glob('s3://noaa-goes16/ABI-L2-SSTF/'+syr+'/'+sjdy+'/*/*.nc'),'SST'\n",
    "    if sat=='goes-west':\n",
    "        file_location,var = fs.glob('s3://noaa-goes17/ABI-L2-SSTF/'+syr+'/'+sjdy+'/*/*.nc'),'SST'\n",
    "    if sat=='himawari':\n",
    "        file_location,var = fs.glob('s3://noaa-himawari8/AHI-L2-FLDK-SST/'+syr+'/'+smon+'/'+sdym+'/*/*L2P*.nc'),'sea_surface_temperature'\n",
    "    \n",
    "    #make a list of links to the file keys\n",
    "    if len(file_location)<1:\n",
    "        return file_ob\n",
    "    file_ob = [fs.open(file) for file in file_location]        #open connection to files\n",
    "    \n",
    "    #open all the day's data\n",
    "    ds = xr.open_mfdataset(file_ob,combine='nested',concat_dim='time') #note file is super messed up formatting\n",
    "    \n",
    "    #clean up coordinates which are a MESS in GOES\n",
    "    #rename one of the coordinates that doesn't match a dim & should\n",
    "    if not sat=='himawari':\n",
    "        ds = ds.rename({'t':'time'})\n",
    "        ds = ds.reset_coords()\n",
    "    else:\n",
    "        ds = ds.rename({'ni':'x','nj':'y'})\n",
    "    \n",
    "    #put in to Celsius\n",
    "    #ds[var] -= 273.15   #nice python shortcut to +- from itself a-=273.15 is the same as a=a-273.15\n",
    "    #ds[var].attrs['units'] = '$^\\circ$C'\n",
    "   \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open a day of GOES-16  (East Coast) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#lyr, idyjl = 2020, 150  #may 30, 2020\n",
    "lyr = 2020\n",
    "for idyjl in range(180,220,5):\n",
    "\n",
    "    ds = get_geo_data('goes-east',lyr,idyjl)\n",
    "\n",
    "    ds.to_zarr('./goes'+str(idyjl)+'_test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy to s3\n",
    "\n",
    "- open up terminal\n",
    "- `pip install aws`\n",
    "- `aws s3 sync ./goes210_test s3://ohw-bucket/goes_zarr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read AWS JMA Himawari SSTs\n",
    "- define a function to get all the filenames for a day\n",
    "- AWS info on Himawari SST data, [here](https://www.goes.noaa.gov/f_himawari-8.html)\n",
    "- Explore S3 structure [here](https://noaa-himawari8.s3.amazonaws.com/index.html)\n",
    "- SSTs are given in L2P and L3C GHRSST data formats.  \n",
    "L2P has dims that not mapped to a regular grid.  \n",
    "L3C is mapped to a grid, with dims lat,lon.\n",
    "\n",
    "Website [https://registry.opendata.aws/noaa-himawari/](https://registry.opendata.aws/noaa-himawari/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lyr, idyjl = 2020, 212\n",
    "\n",
    "ds = get_geo_data('himawari',lyr,idyjl)\n",
    "\n",
    "for var in ds:\n",
    "    if (var=='sea_surface_temperature') or (var=='quality_level'):\n",
    "        continue\n",
    "    ds = ds.drop({var})\n",
    "\n",
    "ds.to_zarr('./himawari.zarr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds = xr.open_zarr('./himawari.zarr')\n",
    "\n",
    "subset = ds.sel(x=slice(-0.05,0.08),y=slice(0.12,0.08))\n",
    "\n",
    "masked = subset.sea_surface_temperature.where(subset.quality_level>=4)\n",
    "\n",
    "mean_dy = masked.mean('time',skipna=True)   #here I want all possible values so skipna=True\n",
    "\n",
    "mean_dy.plot(vmin=14+273.15,vmax=30+273.15,cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ERA5 Data Structure on S3\n",
    "\n",
    "The ERA5 data is organized into NetCDF files per variable, each containing a month of hourly data. \n",
    "The directory structure is `/{year}/{month}/main.nc` for all the variables or `/{year}/{month}/data/{var}.nc` for just a single variable.\n",
    "\n",
    "Variables:\n",
    "- snow_density\n",
    "- sea_surface_temperature\n",
    "- lwe_thickness_of_surface_snow_amount\n",
    "- eastward_wind_at_10_metres\n",
    "- northward_wind_at_10_metres\n",
    "- time1_bounds\n",
    "- air_temperature_at_2_metres_1hour_Maximum\n",
    "- air_temperature_at_2_metres_1hour_Minimum\n",
    "- precipitation_amount_1hour_Accumulation\n",
    "- eastward_wind_at_100_metres\n",
    "- air_temperature_at_2_metres\n",
    "- dew_point_temperature_at_2_metres\n",
    "- integral_wrt_time_of_surface_direct_downwelling_shortwave_flux_in_air_1hour_Accumulation\n",
    "- northward_wind_at_100_metres\n",
    "- air_pressure_at_mean_sea_level\n",
    "- surface_air_pressure\n",
    "\n",
    "For example, the full file path for sea surface temperature for January 2008 is:\n",
    "\n",
    "/2008/01/data/sea_surface_temperature.nc\n",
    "\n",
    "- Note that due to the nature of the ERA5 forecast timing, which is run twice daily at 06:00 and 18:00 UTC, the monthly data file begins with data from 07:00 on the first of the month and continues through 06:00 of the following month. We'll see this in the coordinate values of a data file we download later in the notebook.\n",
    "\n",
    "- Granule variable structure and metadata attributes are stored in main.nc. This file contains coordinate and auxiliary variable data. This file is also annotated using NetCDF CF metadata conventions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_era5(var,lyr):\n",
    "    syr=str(lyr).zfill(4)\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    if var=='all':\n",
    "        file_location = fs.glob('s3://era5-pds/'+syr+'/*/*.nc')\n",
    "    else:\n",
    "        file_location = fs.glob('s3://era5-pds/'+syr+'/*/data/'+var+'*.nc')\n",
    "    file_ob = [fs.open(file) for file in file_location]        \n",
    "    ds=xr.open_mfdataset(file_ob,combine='nested',concat_dim='time0') \n",
    "    #ds['sea_surface_temperature']-=273.15\n",
    "    #ds['sea_surface_temperature'].attrs['units'] = '$^\\circ$C'\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyr=2019\n",
    "ds = get_era5('sea_surface_temperature',lyr)\n",
    "ds = ds.chunk({'time0':500,'time1':500,'lat':100,'lon':100,'nv':2})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_zarr('./era5_zarr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr('./era5_zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play around look at different days to find nice example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lyr = 2020\n",
    "for idyjl in range(210,211):\n",
    "    file = './goes'+str(idyjl)+'.zarr'\n",
    "    if os.path.exists(file):\n",
    "        ds = xr.open_zarr(file)\n",
    "        subset = ds.sel(x=slice(-0.01,0.06),y=slice(0.12,0.09))  #reduce to GS region\n",
    "        masked = subset.SST.where(subset.DQF==0)\n",
    "        mean_dy = masked.mean('time',skipna=True)   #here I want all possible values so skipna=True\n",
    "        mean_dy.plot(vmin=16+273.15,vmax=29+273.15,cmap='inferno')\n",
    "        #plt.savefig('./figs/goes'+str(idyjl)+'.png')\n",
    "        #plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
